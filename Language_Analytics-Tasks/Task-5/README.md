# Assignment 5: Evaluating environmental impact of Language Analytics exam portfolio

This repository contains the code for **Assignment 5** from *Language Analytics* course at *Aarhus University*.

The task of the present assignment is to measure the environmental impact of running the code for the past 4 assignments. ```CodeCarbon``` is used to track this data and provides an approximate value for CO₂ emissions, which are expressed as kilograms of CO₂-equivalent, i.e., (CO₂eq). Then, the CO₂eq values from all assignments are compared to find out which assignment and which task has resulted in greatest CO₂eq values.

This document is structured as follows:

1. **Data and structure** - describes the data source and file structure.
2. **Reproduction instructions** - steps to replicate the analysis.
3. **Output summary** - key points from the outputs.
4. **Ways of improvement** - identifies potential limitations and suggests code enhancements.
5. **CodeCarbon tracking** - environmental impact of running the code.

## 1. Data and structure

The data for this assignment can be found and collected from each assignment's repository, in the folder ```out/emissions```. Data has been gathered and saved in the repository of the present assignment. 

Only the files called **emissions_base... .csv** are considered for this assignment, as the **emissions_assignment_X.csv** files do not show accurate measures, but had to be generated in order to acquire task-specific emission data. In addition, each file has been renamed manually, as it is not possible to set the name for files containing task-specific emission data within the script.

File renaming:

Each **emissions_base... .csv** file from all of the assignments has been renamed with respect to the assignment they were generated in. Therefore, emission data from **assignment 1** has been renamed to *emissions-A-1.csv*, data from **assignment 3** to *emissions-A-3.csv* and so forth, except **assignment 2**, which contains 2 files for emission analysis for each Python script. These files are saved in the folder ```in``` of the present repository.

The overall structure of the folders should be as follows (after step 2 from the section below is completed):

```
assignment-5-LANG/
├── in/
│   ├── emmisions-A-1.csv
│   ├── emmisions-A-2-log.csv
│   ├── emmisions-A-2-neural.csv
│   ├── emmisions-A-3.csv
│   └── emmisions-A-4.csv
├── out/
|   ├── emission_subtasks.png
|   └── total_emissions.png
├── src/
│   └── script-5.ipynb
├── in.zip
├── README.md
└── requirements.txt
```
The **script-5.ipynb** contains all of the code that is required to get the output plots.

## 2. Reproduction instructions

In order to run the Python script smoothly, the following steps should be completed within the terminal:

1. Open the terminal and set the working directory to the folder:

    ```python
    cd your_path_to/assignment-5-LANG
    ```

2. Unzip the datasets:

    ```python
    unzip in.zip
    ```

3. Run the following command to install the required modules:

    ```python
    pip install -r requirements.txt
    ```

4. Run the whole Python notebook. This will create and save 2 plots, which can be found in the folder ```out```.


## 3. Output summary

Once the notebook has completed running, there should appear 2 plots in a folder called ```out```.

**Plot 1**: ```total_emissions.png```

The total amount of emissions was calculated by summing emissions generated by each subtask.

Based on the plot, it seems like the last assignment, namely, **Assignment 4** has generated the most emissions in terms of CO₂eq. Roughly, it generated 0.003 kilograms of CO₂-equivalent. Compared to other assignments, **Assignment 1** has generated a considerably high amount of emissions as well, above 0.002 kilograms of CO₂eq.

Both assignments contained the load and use of the language models, which migh have affected the amount of generated CO₂eq. 


**Plot 2**:  ```emissions_subtasks.png```

This plot showcases the amount of emissions generated in each assignment during each task. It provides a more indepth information on what specifically contributed to the generation of CO₂eq.

- **Assignment 1**.
    
    Based on this subplot, calculation of Relative Frequencies and Unique Entities using a Spacy model on each text file has generated the majority of CO₂eq. Although it did not take much time to run the script, it seems like it was computationally intensive compared to other subtasks of the assignment. 

- **Assignment 2**.
    
    Based on this subplot, the use of the vectorizer to create matrices of numbers for training and testing data has produced the most CO₂eq. Data classification using a neural network has also generated a great amount of CO₂eq. This task consisted of creating and fitting a neural network classifier on the data, and testing it on the testing data as well.

- **Assignment 3**.
    
    Based on this subplot, loading a pretrained *glove-wiki-gigaword-50* language model from *gensim* generated the most CO₂eq. 

- **Assignment 4**.
    
    Based on this subplot, getting a label of emotional profile for the sentences in the dataset has generated the most CO₂eq. This task has also contained creating a classifier for text classification.


## 4. Ways of improvement

As with any programming task, there are always ways of how the code or the analysis can be improved:

- For assignment 2 - it might be better to combine both scripts - for classification with logistic regression and neural network - into one, and make use of ```argparse``` package to let the user choose which type of classification to perform. Since both scripts use the same data and vectorization is identical, the output of such task coul be saved locally, and imported for the next script to run. This way, vectorization would be performed only once. Similar type of improvements could be done for other scripts as well.
- Use less CPUs for running the scripts. Although first 3 assignments were run on 4 CPUs, assignment 4 was run on more and therefore resulted in greatest emissions. To reduce it, it might be better to run the script on less CPUs, and wait for results a bit longer.

## 5. CodeCarbon tracking

This repository contains the analysis of environmental impact of running the code for all 4 assignments using ```CodeCarbon```. 
